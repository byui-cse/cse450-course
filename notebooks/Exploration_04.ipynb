{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HtJm0H1tqTm"
      },
      "source": [
        "# Data Exploration 04\n",
        "\n",
        "You're working with a team of botanists to develop a flower classification system. \n",
        "\n",
        "Your assignment is to build a k-Nearest Neighbors model to classify flowers based on their petal and sepal sizes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s39MWdV8t6UB"
      },
      "source": [
        "## Part A: Import and Explore the data\n",
        "\n",
        "The dataset for this exploration is stored at the following url:\n",
        "\n",
        "[https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/iris.csv](https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/iris.csv)\n",
        "\n",
        "### Initial Data Analysis\n",
        "Once you've loaded the data, it's a good idea to poke around a little bit to find out what you're dealing with.\n",
        "\n",
        "Some questions you might ask include:\n",
        "\n",
        "* What does the data look like?\n",
        "* What kind of data is in each column? \n",
        "* Do any of the columns have missing values?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIyOz1W-kvIR",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Osg2wpr0ul6R",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPlZ1WmWunXB",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr4L8b3ourg-"
      },
      "source": [
        "## Part B: Visualize the Data\n",
        "\n",
        "Use your preferred visualization library to create a scatterplot showing petal length vs petal width. You should plot each flower species as a different color on the scatter plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcsmVzKllukC",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baCxzbklvRbu"
      },
      "source": [
        "## Part C: Prepare the Data for Machine Learning\n",
        "\n",
        "Data preparation (sometimes called \"data wrangling\" or \"data munging\") is where you'll usually spend the bulk of your time when working on machine learning problems. Only rarely is data already in the optimal form for a given algorithm.\n",
        "\n",
        "Often we have to deal with missing values, normalize the data, and perform both simple and complex feature engineering to get the data into the form we need. \n",
        "\n",
        "Once the data is in the correct form, we can then randomize the data and split it into training and test datasets (and sometimes an additional validation dataset).\n",
        "\n",
        "### Machine Learning Steps\n",
        "\n",
        "Almost universally, regardless of which algorithm or type of task we're performing, building and evaluating a machine learning model with sklearn follows these steps:\n",
        "\n",
        "1. Perform any data preprocessing needed.\n",
        "2. Partition the data into features and targets.\n",
        "3. Split the data into training and test sets (and sometimes a third validation set).\n",
        "4. Create a configure whichever sklearn model object we're using.\n",
        "5. Train the model using its \"fit\" method.\n",
        "6. Test the model using its \"predict\" method.\n",
        "7. Use a model evaluation metric to see how well the model performs.\n",
        "\n",
        "If the model isn't performing well, we will repeat one or more of the above steps (sometimes all of them).\n",
        "\n",
        "Once the model is performing adequately, we'll deploy it for use as part of some larger system. \n",
        "\n",
        "For now, let's assume that this dataset is in the form we need, and we'll skip to step 2, partitioning the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoMlhBCrw8qQ"
      },
      "source": [
        "### Step 2. Partition the Data into Features and Targets\n",
        "First, we'll create a dataframe called \"X\" containing the features of the data we want to use to make our predictions. In this case, that will be the `sepal_length`, `sepal_width`, `petal_length`, and `petal_width` features.\n",
        "\n",
        "(The name \"X\" isn't special, but uppercase X is the conventional name for our feature dataset, because that's what statisticians use to refer to a matrix of independent variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhIKMSFmnWD3",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Create a new dataframe called X that contians the features we're going\n",
        "# to use to make predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTk_L5_Xw3VI"
      },
      "source": [
        "Next we'll create a dataframe called \"y\" containing the target variable, or the set of values we want to predict. In this case, that will be `species`.\n",
        "\n",
        "(Once again, the name \"y\" isn't special, but lowercase y is the conventional name for a list of targets, because that's what statisticians use to refer to a vector of dependent variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OiWdSVAnfdV",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Create a new dataframe called y that contians the target we're\n",
        "# trying to predict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmQUnia7xhxn"
      },
      "source": [
        "### Step 3. Split the data into training and test sets.\n",
        "\n",
        "Now that we have our data divided into features (X) and target values (y), we'll split each of these into a training set and a test set.\n",
        "\n",
        "We'll use the training sets to \"train\" our model how to make predictions.\n",
        "\n",
        "We'll then use our test sets to test how well our model has learned from the training data.\n",
        "\n",
        "While we could use a bunch of python code to do this step, the sklearn library has lots of built-in functions to handle common data manipulations related to machine learning.\n",
        "\n",
        "For this step, we'll use the [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2DlWt96ni10",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Import and use the train_test_split() function to split the X and y\n",
        "# dataframes into training and test sets.\n",
        "#\n",
        "# The training data should contain 80% of the samples and\n",
        "# the test data should contain 20% of the samples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf5w0Y1fypww"
      },
      "source": [
        "After creating the training and test splits, output the head() of each one and notice how they row numbers have been randomized. \n",
        "\n",
        "Also notice that X_train and y_train's row numbers match up, as do X_test and y_test's row numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bycoj7HnyoNi",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mb7f5WiVnupq",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgB-4SIwy8LO"
      },
      "source": [
        "## Part D: Create and Train a Model\n",
        "\n",
        "We're going to create a model based on the k-Nearest Neighbors algorithm.\n",
        "\n",
        "Since this is a classification task, (we're trying to classify which species a given flower belongs to), we'll use sklearn's [KNeighborsClassifer](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjWBgtnB0L3i"
      },
      "source": [
        "### Step 4. Create and configure the model\n",
        "\n",
        "We start by importing the information about the model we want to create. In python, this information is called a _class_.\n",
        "\n",
        "The KNeighborsClassifier class contains all of the information python needs to create a kNN Classifier.\n",
        "\n",
        "Once we've imported the class, we'll create an _instance_ of the class using this syntax:\n",
        "\n",
        "    whatever = ClassName( parameter_one = value, parameter_two = something_else, etc...)\n",
        "\n",
        "In our case, the class name is `KNeighborsClassifer`. It doesn't matter what we call the variable that holds the instance, but one popular convention is to call classifier instances `clf`, so that's what you'll see in the sklearn documentation.\n",
        "\n",
        "The only parameter we want to configure is the `n_neighbors` parameter, which controls the value of `k` in the kNN algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KynXQXBRk-nL",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Import the KNeighborsClassifier class from sklearn\n",
        "# Note that it's in the neighbors submodule. See the example code in the\n",
        "# documentation for details on how to import it\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXGAiVEf04Wo",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Create an instance of the model, configuring it to use the 3 nearest neighbors\n",
        "# store the instance in a variable\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4HPfa651GYz"
      },
      "source": [
        "### Step 5: Train the model\n",
        "\n",
        "Next we'll train the model. We do this by providing it with the training data we split off from the dataset in step 3. \n",
        "\n",
        "The model \"learns\" how to associate the feature values (X) with the targets (y). The exact process it uses to learn how to do this depends on which algorithm we're using. \n",
        "\n",
        "Sometimes, this is called \"fitting the data to the model\", so in sklearn, we perform this step using the [fit()](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.fit) method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dizfrzOr1I8a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Call the \"fit\" method of the classifier instance we created in step 4.\n",
        "# Pass it the X_train and y_train data so that it can learn to make predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VicDBl5Me_y4"
      },
      "source": [
        "## Part E: Make Predictions and Evaluate the Model\n",
        "\n",
        "Now that the model has been created and trained, we can use it to make predictions. Since this is a classification model, when we give it a set of features, it tells us what the most likely target value is.\n",
        "\n",
        "In this case, we tell the model \"here are the values for petal width, petal length, sepal width, and sepal length for a particular flower\" The model then tells us which species is the most likely for that flower.\n",
        "\n",
        "When testing how well our model works, we'll use the test data we split off earlier. It contains the measurements for several flowers, along with their species."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9DzR_52ipq-"
      },
      "source": [
        "### Step 6: Make Predictions on Test Data\n",
        "\n",
        "We'll give the measurements of each flower to the model and have it predict their species. We'll then compare those predictions to the known values to determine how accurate our model is.\n",
        "\n",
        "Since this is a classification model, there are two different methods we can use to make predictions:\n",
        "\n",
        "- [predict()](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.predict), which returns the most likely prediction for each sample.\n",
        "\n",
        "- [predict_proba()](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.predict_proba) which returns a list of probabilities for each sample. The probabilities tell us how confident the model is that the corresponding sample belongs to a particular class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1wzEojqoEn_",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Use the predict() method to get a list of predictions for the samples in our \n",
        "# test data. Then output those predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8rNy7hxoNfu",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Just a quick comparison with y_test to see if they match up\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YBap2t2igKT"
      },
      "source": [
        "### Step 7: Evaluate the Model\n",
        "\n",
        "There are several metrics we can use to determine how well our model is performing.\n",
        "\n",
        "Most of them are in the [sklearn.metrics library](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics).\n",
        "\n",
        "Most of the sklearn metric function work using the same pattern. We import the function, then give it a list of the true values for our test data, and a list of the values the model predicted for our test data. The metric then outputs the value. How we interpret that value will depend on the exact problem we're solving, the qualities of our data, and the particular metric we're using."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-na7Ahwl6d2"
      },
      "source": [
        "#### Accuracy \n",
        "Since this is a multiclass classification problem (\"multiclass\" means we have more than two options we're choosing from), we can get a quick estimate from the [accuracy_score()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score) function, which tells us the percent of correct predictions made by the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZndOJI6XoP46",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Import the accuracy_score function and use it to determine\n",
        "# how accurate the models predictions were for our test data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZh218e_kuqw"
      },
      "source": [
        "#### Confusion Matrix\n",
        "While the accuracy score tells us a little about the model's performance, it doesn't tell us much.\n",
        "\n",
        "For example, we know how often the model was correct, but we don't know when it was wrong or why.\n",
        "\n",
        "We can get this information from the [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix) function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqyBO7NRpjjB",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Import the confusion_matrix function and use it to generate a confusion\n",
        "# matrix of our model results.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "A_bfx9e7lv9r"
      },
      "source": [
        "#### Confusion Matrix Plot\n",
        "\n",
        "It's easier to see the results of the confusion matrix if we plot the results. The easiest way to do this is with the [confusion matrix](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html) function. \n",
        "\n",
        "This function works a little bit differently than the others. It takes as parameters your model instance, and the X_test and y_test data frames, and outputs a confusion matrix showing how well the model did in predicting the target values. \n",
        "\n",
        "You'll notice that in many cases (including this one), the numbers in the confusion matrix will be the same as the results you see from the confusion_matrix() function above, but the plot makes it easier to interpret the results.\n",
        "\n",
        "When using the confusion matrix, you may find that the default color mapping is difficult to read. The \"Blues\" mapping is a popular choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CuFoRyHp6fu",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Import the plot_confusion_matrix function and use it to plot the confusion\n",
        "# matrix for the test data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyrxIM5ZuBsJ"
      },
      "source": [
        "## ðŸŒŸ Above and Beyond ðŸŒŸ\n",
        "\n",
        "Once you've complted the basics, try to complete one or more of the following tasks:\n",
        "\n",
        "1. See if you can get better results from your model through some data preprocessing, such as normalization.\n",
        "\n",
        "2. Often, using too many features can give poor results. Can you get better performance using a subset of the features instead of all four?\n",
        "\n",
        "3. Are there other ways you could visualize your model results?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPdu/6oryRihr+7b8w51NlX",
      "collapsed_sections": [],
      "name": "DataExploration_04.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
